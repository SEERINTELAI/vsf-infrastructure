---
# deploy-mock-dcgm.yml
# Deploy mock-dcgm-exporter Helm chart to K3s cluster (Task 111)
#
# Usage:
#   ansible-playbook -i inventory/vsf.yml monitoring/deploy-mock-dcgm.yml
#
# Prerequisites:
#   - K3s cluster running (Tasks 105-109)
#   - Helm installed on control plane
#   - GPU nodes joined with labels

- name: Deploy mock-dcgm-exporter
  hosts: control_plane[0]
  become: true
  vars:
    helm_chart_path: "{{ playbook_dir }}/../../helm/mock-dcgm-exporter"
    release_name: mock-dcgm-exporter
    namespace: gpu-monitoring
    
    # Mock GPU configuration
    gpus_per_node: 1
    gpu_model: "NVIDIA RTX 4090"
    gpu_memory_mib: 24576
    workload_profile: "moderate"
    
  tasks:
    - name: Ensure Helm is installed
      block:
        - name: Check if Helm is installed
          command: helm version --short
          register: helm_check
          changed_when: false
          failed_when: false
        
        - name: Install Helm if not present
          when: helm_check.rc != 0
          shell: |
            curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          args:
            creates: /usr/local/bin/helm
    
    - name: Create gpu-monitoring namespace
      command: k3s kubectl create namespace {{ namespace }} --dry-run=client -o yaml
      register: ns_yaml
      changed_when: false
    
    - name: Apply namespace
      command: k3s kubectl apply -f -
      args:
        stdin: "{{ ns_yaml.stdout }}"
    
    - name: Copy Helm chart to control plane
      synchronize:
        src: "{{ helm_chart_path }}/"
        dest: /tmp/mock-dcgm-exporter/
        delete: yes
      delegate_to: "{{ inventory_hostname }}"
    
    - name: Create values override file
      copy:
        dest: /tmp/mock-dcgm-values.yaml
        mode: '0644'
        content: |
          # VSF Mock DCGM Exporter Configuration
          # Generated by Ansible deploy-mock-dcgm.yml
          
          gpuSimulation:
            gpusPerNode: {{ gpus_per_node }}
            gpuModel: "{{ gpu_model }}"
            gpuMemoryMiB: {{ gpu_memory_mib }}
            defaultProfile: "{{ workload_profile }}"
          
          # Ensure we target GPU nodes
          nodeSelector:
            vsf/node-type: gpu
          
          # Tolerate GPU taints
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
          
          # Enable Prometheus ServiceMonitor
          serviceMonitor:
            enabled: true
            interval: 15s
            labels:
              release: prometheus
    
    - name: Deploy mock-dcgm-exporter with Helm
      environment:
        KUBECONFIG: /etc/rancher/k3s/k3s.yaml
      command: >
        helm upgrade --install {{ release_name }}
        /tmp/mock-dcgm-exporter
        --namespace {{ namespace }}
        --values /tmp/mock-dcgm-values.yaml
        --wait
        --timeout 5m
      register: helm_install
    
    - name: Display Helm output
      debug:
        msg: "{{ helm_install.stdout_lines }}"
    
    - name: Wait for DaemonSet to be ready
      command: >
        k3s kubectl rollout status daemonset/{{ release_name }}
        -n {{ namespace }} --timeout=120s
      register: rollout_status
      retries: 3
      delay: 10
      until: rollout_status.rc == 0


- name: Validate mock-dcgm-exporter deployment
  hosts: control_plane[0]
  become: true
  vars:
    namespace: gpu-monitoring
    release_name: mock-dcgm-exporter
    
  tasks:
    - name: Get DaemonSet status
      command: k3s kubectl get daemonset {{ release_name }} -n {{ namespace }} -o wide
      register: daemonset_status
      changed_when: false
    
    - name: Display DaemonSet status
      debug:
        msg: "{{ daemonset_status.stdout_lines }}"
    
    - name: Get pods
      command: k3s kubectl get pods -n {{ namespace }} -l app.kubernetes.io/name=mock-dcgm-exporter -o wide
      register: pods_status
      changed_when: false
    
    - name: Display pods
      debug:
        msg: "{{ pods_status.stdout_lines }}"
    
    - name: Test metrics endpoint from a pod
      shell: |
        POD=$(k3s kubectl get pods -n {{ namespace }} -l app.kubernetes.io/name=mock-dcgm-exporter -o jsonpath='{.items[0].metadata.name}')
        k3s kubectl exec -n {{ namespace }} $POD -- wget -qO- http://localhost:9400/metrics 2>/dev/null | head -30
      register: metrics_test
      changed_when: false
      failed_when: false
    
    - name: Display sample metrics
      debug:
        msg: "{{ metrics_test.stdout_lines }}"
    
    - name: Verify DCGM metrics are present
      shell: |
        POD=$(k3s kubectl get pods -n {{ namespace }} -l app.kubernetes.io/name=mock-dcgm-exporter -o jsonpath='{.items[0].metadata.name}')
        k3s kubectl exec -n {{ namespace }} $POD -- wget -qO- http://localhost:9400/metrics 2>/dev/null | grep -c "DCGM_FI_DEV"
      register: dcgm_metric_count
      changed_when: false
      failed_when: dcgm_metric_count.stdout | int < 5
    
    - name: Deployment summary
      debug:
        msg: |
          ========================================
          Mock DCGM Exporter Deployment Complete
          ========================================
          Namespace: {{ namespace }}
          Release: {{ release_name }}
          
          DaemonSet:
          {{ daemonset_status.stdout }}
          
          Metrics endpoint: :9400/metrics
          DCGM metrics found: {{ dcgm_metric_count.stdout }}
          
          Next Steps:
          1. Configure Prometheus to scrape (ServiceMonitor created)
          2. Import GPU Grafana dashboard
          3. Verify metrics in Prometheus UI
          ========================================
