"""
Monitoring Test Suite for VSF F10.2

Tests Prometheus, Grafana, GPU metrics, and power monitoring stack.
Implements DP:ETG with 15+ tests and pre-mortem failure categories.

Pre-Mortem Categories:
1. Service Availability - Components not running
2. Metrics Collection - Scrape targets unreachable or stale
3. Data Integrity - Metrics malformed or missing labels
4. Alerting - Alert rules not firing or misconfigured
5. Dashboard - Grafana datasources or panels broken
6. Resource Exhaustion - Storage/memory limits exceeded

Usage:
    pytest tests/test_monitoring.py -v
    pytest tests/test_monitoring.py -v -m "gpu_metrics"
    pytest tests/test_monitoring.py -v -m "power_metrics"
"""

import subprocess
import json
import re
from typing import Optional
import pytest


# =============================================================================
# Fixtures
# =============================================================================

@pytest.fixture
def kubectl():
    """Fixture to run kubectl commands."""
    def _kubectl(args: str, namespace: Optional[str] = None) -> subprocess.CompletedProcess:
        cmd = ["kubectl"]
        if namespace:
            cmd.extend(["-n", namespace])
        cmd.extend(args.split())
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result
    
    # Check if kubectl is available
    result = subprocess.run(["which", "kubectl"], capture_output=True)
    if result.returncode != 0:
        pytest.skip("kubectl not available")
    return _kubectl


@pytest.fixture
def prometheus_url():
    """Get Prometheus service URL."""
    return "http://prometheus-server.monitoring.svc.cluster.local:9090"


@pytest.fixture
def grafana_url():
    """Get Grafana service URL."""
    return "http://grafana.monitoring.svc.cluster.local:3000"


# =============================================================================
# Category 1: Service Availability (3 tests)
# Pre-mortem: What if monitoring services aren't running?
# =============================================================================

class TestServiceAvailability:
    """Tests for monitoring service availability."""
    
    @pytest.mark.service_availability
    def test_prometheus_deployment_running(self, kubectl):
        """Verify Prometheus server deployment is running."""
        result = kubectl("get deployment prometheus-server -o jsonpath='{.status.readyReplicas}'", 
                        namespace="monitoring")
        if result.returncode != 0:
            pytest.skip("Prometheus not deployed yet")
        
        ready = result.stdout.strip("'")
        assert ready and int(ready) >= 1, f"Prometheus not ready: {ready} replicas"
    
    @pytest.mark.service_availability
    def test_grafana_deployment_running(self, kubectl):
        """Verify Grafana deployment is running."""
        result = kubectl("get deployment grafana -o jsonpath='{.status.readyReplicas}'",
                        namespace="monitoring")
        if result.returncode != 0:
            pytest.skip("Grafana not deployed yet")
        
        ready = result.stdout.strip("'")
        assert ready and int(ready) >= 1, f"Grafana not ready: {ready} replicas"
    
    @pytest.mark.service_availability
    @pytest.mark.gpu_metrics
    def test_mock_dcgm_exporter_daemonset_running(self, kubectl):
        """Verify mock-dcgm-exporter DaemonSet is running on GPU nodes."""
        result = kubectl("get daemonset mock-dcgm-exporter -o json",
                        namespace="gpu-monitoring")
        if result.returncode != 0:
            pytest.skip("mock-dcgm-exporter not deployed yet")
        
        ds = json.loads(result.stdout)
        desired = ds["status"].get("desiredNumberScheduled", 0)
        ready = ds["status"].get("numberReady", 0)
        
        assert desired > 0, "No GPU nodes available for DaemonSet"
        assert ready == desired, f"DaemonSet not fully ready: {ready}/{desired}"


# =============================================================================
# Category 2: Metrics Collection (4 tests)
# Pre-mortem: What if scrape targets are unreachable or stale?
# =============================================================================

class TestMetricsCollection:
    """Tests for Prometheus metrics collection."""
    
    @pytest.mark.metrics_collection
    def test_prometheus_scrape_targets_healthy(self, kubectl):
        """Verify Prometheus scrape targets are up."""
        # This would normally query Prometheus API
        # For now, check ServiceMonitors exist
        result = kubectl("get servicemonitor -A -o json")
        if result.returncode != 0:
            pytest.skip("ServiceMonitor CRD not available")
        
        monitors = json.loads(result.stdout)
        assert len(monitors.get("items", [])) > 0, "No ServiceMonitors configured"
    
    @pytest.mark.metrics_collection
    @pytest.mark.gpu_metrics
    def test_gpu_metrics_endpoint_reachable(self, kubectl):
        """Verify GPU metrics endpoint responds."""
        # Get a mock-dcgm-exporter pod
        result = kubectl("get pods -l app.kubernetes.io/name=mock-dcgm-exporter -o jsonpath='{.items[0].metadata.name}'",
                        namespace="gpu-monitoring")
        if result.returncode != 0 or not result.stdout.strip("'"):
            pytest.skip("No mock-dcgm-exporter pods found")
        
        pod_name = result.stdout.strip("'")
        
        # Exec into pod and curl metrics
        result = kubectl(f"exec {pod_name} -- wget -qO- http://localhost:9400/metrics",
                        namespace="gpu-monitoring")
        
        assert result.returncode == 0, f"Failed to reach metrics endpoint: {result.stderr}"
        assert "DCGM_FI_DEV" in result.stdout, "GPU metrics not found in response"
    
    @pytest.mark.metrics_collection
    @pytest.mark.power_metrics
    def test_power_metrics_endpoint_reachable(self, kubectl):
        """Verify power metrics endpoint responds."""
        # Get a synthetic-power-exporter pod
        result = kubectl("get pods -l app.kubernetes.io/name=synthetic-power-exporter -o jsonpath='{.items[0].metadata.name}'",
                        namespace="power-monitoring")
        if result.returncode != 0 or not result.stdout.strip("'"):
            pytest.skip("No synthetic-power-exporter pods found")
        
        pod_name = result.stdout.strip("'")
        
        # Exec into pod and curl metrics
        result = kubectl(f"exec {pod_name} -- wget -qO- http://localhost:9100/metrics",
                        namespace="power-monitoring")
        
        assert result.returncode == 0, f"Failed to reach power metrics: {result.stderr}"
        # Check for Kepler-compatible metrics or synthetic equivalents
        assert "kepler_" in result.stdout or "node_power" in result.stdout, \
            "Power metrics not found in response"
    
    @pytest.mark.metrics_collection
    def test_node_exporter_metrics_available(self, kubectl):
        """Verify node-exporter metrics are being collected."""
        result = kubectl("get daemonset prometheus-node-exporter -o json",
                        namespace="monitoring")
        if result.returncode != 0:
            pytest.skip("node-exporter not deployed")
        
        ds = json.loads(result.stdout)
        ready = ds["status"].get("numberReady", 0)
        desired = ds["status"].get("desiredNumberScheduled", 0)
        
        assert ready == desired, f"node-exporter not on all nodes: {ready}/{desired}"


# =============================================================================
# Category 3: Data Integrity (3 tests)
# Pre-mortem: What if metrics are malformed or missing labels?
# =============================================================================

class TestDataIntegrity:
    """Tests for metrics data integrity."""
    
    @pytest.mark.data_integrity
    @pytest.mark.gpu_metrics
    def test_gpu_metrics_have_required_labels(self, kubectl):
        """Verify GPU metrics have required labels (gpu, UUID, hostname)."""
        result = kubectl("get pods -l app.kubernetes.io/name=mock-dcgm-exporter -o jsonpath='{.items[0].metadata.name}'",
                        namespace="gpu-monitoring")
        if result.returncode != 0 or not result.stdout.strip("'"):
            pytest.skip("No mock-dcgm-exporter pods found")
        
        pod_name = result.stdout.strip("'")
        result = kubectl(f"exec {pod_name} -- wget -qO- http://localhost:9400/metrics",
                        namespace="gpu-monitoring")
        
        if result.returncode != 0:
            pytest.skip("Cannot reach metrics endpoint")
        
        metrics = result.stdout
        
        # Check required labels exist
        required_labels = ["gpu=", "UUID=", "Hostname="]
        for label in required_labels:
            assert label in metrics, f"Missing required label: {label}"
    
    @pytest.mark.data_integrity
    @pytest.mark.gpu_metrics
    def test_gpu_metrics_values_in_range(self, kubectl):
        """Verify GPU metric values are within expected ranges."""
        result = kubectl("get pods -l app.kubernetes.io/name=mock-dcgm-exporter -o jsonpath='{.items[0].metadata.name}'",
                        namespace="gpu-monitoring")
        if result.returncode != 0 or not result.stdout.strip("'"):
            pytest.skip("No mock-dcgm-exporter pods found")
        
        pod_name = result.stdout.strip("'")
        result = kubectl(f"exec {pod_name} -- wget -qO- http://localhost:9400/metrics",
                        namespace="gpu-monitoring")
        
        if result.returncode != 0:
            pytest.skip("Cannot reach metrics endpoint")
        
        metrics = result.stdout
        
        # Parse and validate GPU utilization (0-100)
        util_match = re.search(r'DCGM_FI_DEV_GPU_UTIL\{[^}]+\}\s+(\d+\.?\d*)', metrics)
        if util_match:
            util_value = float(util_match.group(1))
            assert 0 <= util_value <= 100, f"GPU util out of range: {util_value}"
        
        # Parse and validate temperature (0-120Â°C reasonable for GPUs)
        temp_match = re.search(r'DCGM_FI_DEV_GPU_TEMP\{[^}]+\}\s+(\d+\.?\d*)', metrics)
        if temp_match:
            temp_value = float(temp_match.group(1))
            assert 0 <= temp_value <= 120, f"GPU temp out of range: {temp_value}"
    
    @pytest.mark.data_integrity
    def test_metrics_timestamps_recent(self, kubectl):
        """Verify metrics are being updated (not stale)."""
        # This would query Prometheus for up{} metrics with timestamps
        # For now, verify pods are in Running state (implies active metrics)
        result = kubectl("get pods -l app.kubernetes.io/name=mock-dcgm-exporter -o jsonpath='{.items[*].status.phase}'",
                        namespace="gpu-monitoring")
        if result.returncode != 0:
            pytest.skip("Cannot check pod status")
        
        phases = result.stdout.strip("'").split()
        for phase in phases:
            assert phase == "Running", f"Pod not running: {phase}"


# =============================================================================
# Category 4: Alerting (2 tests)
# Pre-mortem: What if alert rules don't fire or are misconfigured?
# =============================================================================

class TestAlerting:
    """Tests for Prometheus alerting configuration."""
    
    @pytest.mark.alerting
    def test_prometheus_alertmanager_connected(self, kubectl):
        """Verify Prometheus is connected to Alertmanager."""
        result = kubectl("get deployment alertmanager -o json",
                        namespace="monitoring")
        if result.returncode != 0:
            pytest.skip("Alertmanager not deployed")
        
        am = json.loads(result.stdout)
        ready = am["status"].get("readyReplicas", 0)
        assert ready >= 1, "Alertmanager not ready"
    
    @pytest.mark.alerting
    def test_gpu_alert_rules_configured(self, kubectl):
        """Verify GPU-related alert rules exist."""
        result = kubectl("get prometheusrule -A -o json")
        if result.returncode != 0:
            pytest.skip("PrometheusRule CRD not available")
        
        rules = json.loads(result.stdout)
        # Check that some rules exist (specific GPU rules optional for mock mode)
        item_count = len(rules.get("items", []))
        # In mock mode, we may not have GPU-specific alerts yet
        if item_count == 0:
            pytest.skip("No PrometheusRules configured (expected in mock mode)")


# =============================================================================
# Category 5: Dashboard (2 tests)
# Pre-mortem: What if Grafana datasources or panels are broken?
# =============================================================================

class TestDashboard:
    """Tests for Grafana dashboard configuration."""
    
    @pytest.mark.dashboard
    def test_grafana_prometheus_datasource_configured(self, kubectl):
        """Verify Grafana has Prometheus datasource."""
        result = kubectl("get configmap grafana-datasources -o json",
                        namespace="monitoring")
        if result.returncode != 0:
            pytest.skip("Grafana datasources ConfigMap not found")
        
        cm = json.loads(result.stdout)
        data = cm.get("data", {})
        
        # Check for prometheus datasource in any key
        datasource_found = False
        for key, value in data.items():
            if "prometheus" in value.lower():
                datasource_found = True
                break
        
        assert datasource_found, "Prometheus datasource not configured in Grafana"
    
    @pytest.mark.dashboard
    def test_gpu_dashboard_exists(self, kubectl):
        """Verify GPU monitoring dashboard is provisioned."""
        result = kubectl("get configmap -l grafana_dashboard=1 -o json",
                        namespace="monitoring")
        if result.returncode != 0:
            pytest.skip("No Grafana dashboards found")
        
        cms = json.loads(result.stdout)
        dashboards = cms.get("items", [])
        
        # Look for GPU-related dashboard
        gpu_dashboard_found = False
        for dashboard in dashboards:
            name = dashboard.get("metadata", {}).get("name", "").lower()
            if "gpu" in name or "dcgm" in name:
                gpu_dashboard_found = True
                break
        
        if not gpu_dashboard_found:
            pytest.skip("GPU dashboard not provisioned yet (expected in mock mode)")


# =============================================================================
# Category 6: Resource Exhaustion (2 tests)
# Pre-mortem: What if storage/memory limits are exceeded?
# =============================================================================

class TestResourceExhaustion:
    """Tests for monitoring resource limits."""
    
    @pytest.mark.resource_exhaustion
    def test_prometheus_storage_not_full(self, kubectl):
        """Verify Prometheus storage is not exhausted."""
        result = kubectl("get pvc prometheus-server -o json",
                        namespace="monitoring")
        if result.returncode != 0:
            pytest.skip("Prometheus PVC not found (may use emptyDir)")
        
        pvc = json.loads(result.stdout)
        phase = pvc.get("status", {}).get("phase", "")
        assert phase == "Bound", f"PVC not bound: {phase}"
    
    @pytest.mark.resource_exhaustion
    def test_monitoring_pods_not_oom_killed(self, kubectl):
        """Verify monitoring pods haven't been OOM killed."""
        result = kubectl("get pods -o json", namespace="monitoring")
        if result.returncode != 0:
            pytest.skip("Cannot get monitoring pods")
        
        pods = json.loads(result.stdout)
        
        for pod in pods.get("items", []):
            pod_name = pod.get("metadata", {}).get("name", "unknown")
            container_statuses = pod.get("status", {}).get("containerStatuses", [])
            
            for status in container_statuses:
                last_state = status.get("lastState", {})
                terminated = last_state.get("terminated", {})
                reason = terminated.get("reason", "")
                
                assert reason != "OOMKilled", \
                    f"Pod {pod_name} was OOM killed"


# =============================================================================
# Integration Tests (2 tests)
# End-to-end verification of monitoring pipeline
# =============================================================================

class TestMonitoringIntegration:
    """End-to-end integration tests for monitoring."""
    
    @pytest.mark.integration
    @pytest.mark.gpu_metrics
    def test_gpu_metrics_in_prometheus(self, kubectl):
        """Verify GPU metrics are queryable in Prometheus."""
        # This would normally curl Prometheus API
        # For now, verify the pipeline components are connected
        result = kubectl("get servicemonitor mock-dcgm-exporter -o json",
                        namespace="gpu-monitoring")
        if result.returncode != 0:
            pytest.skip("ServiceMonitor not found")
        
        sm = json.loads(result.stdout)
        endpoints = sm.get("spec", {}).get("endpoints", [])
        assert len(endpoints) > 0, "ServiceMonitor has no endpoints"
        
        # Verify endpoint configuration
        endpoint = endpoints[0]
        assert endpoint.get("port") == "metrics", "Wrong port name in ServiceMonitor"
    
    @pytest.mark.integration
    def test_full_monitoring_stack_health(self, kubectl):
        """Verify entire monitoring stack is healthy."""
        components = [
            ("deployment", "prometheus-server", "monitoring"),
            ("daemonset", "prometheus-node-exporter", "monitoring"),
        ]
        
        healthy_count = 0
        for kind, name, namespace in components:
            result = kubectl(f"get {kind} {name} -o json", namespace=namespace)
            if result.returncode == 0:
                obj = json.loads(result.stdout)
                if kind == "deployment":
                    ready = obj.get("status", {}).get("readyReplicas", 0)
                else:  # daemonset
                    ready = obj.get("status", {}).get("numberReady", 0)
                
                if ready and ready > 0:
                    healthy_count += 1
        
        # At least some components should be healthy
        assert healthy_count > 0, "No monitoring components are healthy"


# =============================================================================
# Test Summary
# =============================================================================
# Total: 17 tests
#
# Category 1 - Service Availability: 3 tests
# Category 2 - Metrics Collection: 4 tests  
# Category 3 - Data Integrity: 3 tests
# Category 4 - Alerting: 2 tests
# Category 5 - Dashboard: 2 tests
# Category 6 - Resource Exhaustion: 2 tests
# Integration: 2 tests (bonus)
#
# Markers:
#   - service_availability
#   - metrics_collection
#   - data_integrity
#   - alerting
#   - dashboard
#   - resource_exhaustion
#   - integration
#   - gpu_metrics
#   - power_metrics
# =============================================================================
